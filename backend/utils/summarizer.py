# Import the LLM interface to call for summaries
from backend.llm import react_with_llm
import nltk
from nltk.tokenize import sent_tokenize

def _ensure_nltk_data():
    """Ensure NLTK punkt tokenizer is available"""
    try:
        nltk.data.find('tokenizers/punkt')
    except LookupError:
        try:
            nltk.download("punkt", quiet=True)
            nltk.download("punkt_tab", quiet=True)  # For newer NLTK versions
        except Exception as e:
            print(f"Warning: Could not download NLTK data: {e}")
            # Fallback to simple sentence splitting
            return False
    return True

def _simple_sentence_split(text):
    """Fallback sentence splitting when NLTK is not available"""
    import re
    # Simple regex-based sentence splitting
    sentences = re.split(r'[.!?]+\s+', text)
    return [s.strip() for s in sentences if s.strip()]

def summarize_text(text: str, format: str = "paragraph") -> str:
    """
    Generates a summary of the provided document text in either paragraph or bullet-point format using the LLM.

    Parameters:
    - text (str): The full document content as a string.
    - format (str): "paragraph" or "bullets"

    Returns:
    - str: The summary generated by the LLM.
    """
    if not text.strip():
        return "No content to summarize."

    # Ensure NLTK data is available
    if not _ensure_nltk_data():
        print("Warning: Using fallback sentence splitting")

    # Trim large documents
    snippet = text[:3000]

    # Construct the prompt
    if format == "bullets":
        prompt = f"Summarize the following document in bullet points:\n\n{snippet}"
    else:
        prompt = f"Summarize the following document:\n\n{snippet}"

    messages = [{"role": "user", "content": prompt}]

    try:
        return react_with_llm(messages)
    except Exception as e:
        print(f"[LLM Error] {e}")
        return "Summary generation failed."


